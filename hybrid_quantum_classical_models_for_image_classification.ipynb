{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GmOP-3aIKWR"
   },
   "outputs": [],
   "source": [
    "#Samar Abdelghani\n",
    "# the reproduced paper: https://doi.org/10.1088/2632-2153/ad2aef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8Vlv6pJw5E-",
    "outputId": "deec7412-cb90-4ac5-9df2-9efcc800c705",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#uncomment to run on Google Colab\n",
    "#!pip install torch torchvision\n",
    "#!pip install pennylane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GiQCqY_Extm4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2y_MijfDyz94"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKRXxrY8y-iV",
    "outputId": "df794bb7-8af7-418f-cc3c-90de96a7918a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32I50hEsy_tD",
    "outputId": "49f5a921-798e-4761-ec1e-9f9537ece41c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Download and load MNIST dataset\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True,\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HZ3-vskd0EAU"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pennylane as qml\n",
    "\n",
    "# Define the quantum circuit using PennyLane\n",
    "n_qubits = 5\n",
    "if use_cuda is True:\n",
    "    dev = qml.device(\"lightning.gpu\", wires=n_qubits)\n",
    "else:\n",
    "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "# Define the QLayer\n",
    "n_layers = 3\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
    "\n",
    "\n",
    "# Define a simple CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Convolutional layer 1 with 1 input channels (for greyscale images), 16 output channels, and 5x5 kernel\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, stride=1, padding=2)\n",
    "        # Batch normalization after convolutional layer 1\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        # Max pooling layer with a 2x2 window\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Convolutional layer 2 with 16 input channels (from the previous layer), 32 output channels, and 5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, stride=1, padding=2)\n",
    "        # Batch normalization after convolutional layer 2\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        # Quantum layer\n",
    "        self.qlayer1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer3 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer4 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 120)\n",
    "        self.fc2 = nn.Linear(120, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Propagate the input through the CNN layers\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        # Flatten the output from the convolutional layers\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        # Pass the output to the quantum layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x_1, x_2, x_3, x_4 = torch.split(x, 5, dim=1)\n",
    "        x_1 = self.qlayer1(x_1)\n",
    "        x_2 = self.qlayer2(x_2)\n",
    "        x_3 = self.qlayer3(x_3)\n",
    "        x_4 = self.qlayer4(x_4)\n",
    "        x = torch.cat([x_1, x_2, x_3, x_4], axis=1)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8Q7uxYA0eeG",
    "outputId": "595a711c-8886-45a8-fe69-41c5cae70411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, 2025-08-11 22:32:15.050618\n",
      "epoch=1, 2025-08-11 22:41:36.876982\n",
      "epoch=2, 2025-08-11 22:50:56.686454\n",
      "epoch=3, 2025-08-11 23:00:34.820794\n",
      "epoch=4, 2025-08-11 23:09:29.921516\n",
      "epoch=5, 2025-08-11 23:16:34.625171\n",
      "epoch=6, 2025-08-11 23:23:28.576257\n",
      "epoch=7, 2025-08-11 23:30:20.387858\n",
      "epoch=8, 2025-08-11 23:37:13.235210\n",
      "epoch=9, 2025-08-11 23:44:06.311474\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "dataset  = train_data\n",
    "\n",
    "# Initialize your CNN model\n",
    "cnn = Net()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)  # Stochastic Gradient Descent optimizer\n",
    "# Split your data into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True)\n",
    "#val_loader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=False)\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    ct = datetime.datetime.now()\n",
    "    print(f\"{epoch=}, {ct}\")\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients to avoid accumulation\n",
    "        outputs = cnn(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update the model parameters\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dstIODIGr3ba"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pd4QOyg206Qg",
    "outputId": "87271ef5-b01d-4710-9168-5435c760db9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 99.17%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# Set the model to evaluation mode\n",
    "cnn.eval()\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        outputs = cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy on the validation set: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF0sLNEOsy4a"
   },
   "outputs": [],
   "source": [
    "#Testing the classical network without Quantum computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fRmswkxloZII"
   },
   "outputs": [],
   "source": [
    "# Define a simple CNN architecture\n",
    "class Pure_classical_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Pure_classical_Net, self).__init__()\n",
    "        # Convolutional layer 1 with 1 input channels (for greyscale images), 16 output channels, and 5x5 kernel\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, stride=1, padding=2)\n",
    "        # Batch normalization after convolutional layer 1\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        # Max pooling layer with a 2x2 window\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Convolutional layer 2 with 16 input channels (from the previous layer), 32 output channels, and 5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, stride=1, padding=2)\n",
    "        # Batch normalization after convolutional layer 2\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 120)\n",
    "        self.fc2 = nn.Linear(120, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Propagate the input through the CNN layers\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        # Flatten the output from the convolutional layers\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        # Pass the output to the quantum layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcaztUU-tCdm",
    "outputId": "f5d0cfa6-3e79-4a08-9426-e9a831ed8738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "dataset  = train_data\n",
    "\n",
    "# Initialize your CNN model\n",
    "class_cnn = Pure_classical_Net()\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = torch.optim.SGD(class_cnn.parameters(), lr=0.001, momentum=0.9)  # Stochastic Gradient Descent optimizer\n",
    "# Split your data into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=False)\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients to avoid accumulation\n",
    "        outputs = class_cnn(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update the model parameters\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q67AOAfVtLO6",
    "outputId": "ce8a3942-a765-4b6a-821e-3ebc0f2a7c1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 99.18%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# Set the model to evaluation mode\n",
    "class_cnn.eval()\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        outputs = class_cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy on the validation set: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Z0Ahfvbyw9Gx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
